{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np # Matrix and vector computation package\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import math\n",
    "import time\n",
    "# Allow matplotlib to plot inside this notebook\n",
    "%matplotlib inline\n",
    "# Set the seed of the numpy random number generator so that the tutorial is reproducable\n",
    "np.random.seed(seed=1)\n",
    "from sklearn import datasets, metrics # data and evaluation utils\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import colorConverter, ListedColormap # some plotting functions\n",
    "import itertools\n",
    "import collections\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>DATASET FEATURE SPACE<<<<<<\n",
      ">>>TRAIN<<<\n",
      "(42000, 784)\n",
      "(42000, 10)\n",
      ">>>VALIDATION<<<\n",
      "(14000, 784)\n",
      "(14000, 10)\n",
      ">>>TEST<<<\n",
      "(14000, 784)\n",
      "(14000, 10)\n"
     ]
    }
   ],
   "source": [
    "# load the data from scikit-learn.\n",
    "digits = fetch_openml('mnist_784')\n",
    "\n",
    "\n",
    "# Load the targets.\n",
    "# Note that the targets are stored as digits, these need to be \n",
    "#  converted to one-hot-encoding for the output sofmax layer.\n",
    "n = digits.target.shape[0]\n",
    "T = np.zeros((n,10))\n",
    "T[np.arange(len(T)), digits.target.astype(int)] += 1\n",
    "# Divide the data into a train and test set.\n",
    "X_train, X_test, T_train, T_test = train_test_split(\n",
    "    digits.data, T, test_size=0.4)\n",
    "# Divide the test set into a validation set and final test set.\n",
    "X_validation, X_test, T_validation, T_test = train_test_split(\n",
    "    X_test, T_test, test_size=0.5)\n",
    "print(\">>>>>>DATASET FEATURE SPACE<<<<<<\")\n",
    "print(\">>>TRAIN<<<\")\n",
    "print(X_train.shape)\n",
    "print(T_train.shape)\n",
    "print(\">>>VALIDATION<<<\")\n",
    "print(X_validation.shape)\n",
    "print(T_validation.shape)\n",
    "print(\">>>TEST<<<\")                              \n",
    "print(X_test.shape)\n",
    "print(T_test.shape)\n",
    "\n",
    "#with open(\"T_TEST_DATA.csv\",\"w\") as my_csv:\n",
    "#    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "#    csvWriter.writerows(T_test)\n",
    "\n",
    "#with open(\"X_TEST_DATA.csv\",\"w\") as my_csv:\n",
    "#    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "#    csvWriter.writerows(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the non-linear functions used\n",
    "def logistic(z): \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_deriv(y):  # Derivative of logistic function\n",
    "    return np.multiply(y, (1 - y))\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(x, 0, x)\n",
    "\n",
    "def ReLU_Der(out):\n",
    "    out[out<=0] = 0\n",
    "    out[out>0] = 1\n",
    "    return out\n",
    "\n",
    "def softmax(z): \n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \"\"\"Base class for the different layers.\n",
    "    Defines base methods and documentation of methods.\"\"\"\n",
    "    \n",
    "    def get_params_iter(self):\n",
    "        \"\"\"Return an iterator over the parameters (if any).\n",
    "        The iterator has the same order as get_params_grad.\n",
    "        The elements returned by the iterator are editable in-place.\"\"\"\n",
    "        return []\n",
    "    \n",
    "    def get_params_grad(self, X, output_grad):\n",
    "        \"\"\"Return a list of gradients over the parameters.\n",
    "        The list has the same order as the get_params_iter iterator.\n",
    "        X is the input.\n",
    "        output_grad is the gradient at the output of this layer.\n",
    "        \"\"\"\n",
    "        return []\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        \"\"\"Perform the forward step linear transformation.\n",
    "        X is the input.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_input_grad(self, Y, output_grad=None, T=None):\n",
    "        \"\"\"Return the gradient at the inputs of this layer.\n",
    "        Y is the pre-computed output of this layer (not needed in this case).\n",
    "        output_grad is the gradient at the output of this layer \n",
    "         (gradient at input of next layer).\n",
    "        Output layer uses targets T to compute the gradient based on the \n",
    "         output error instead of output_grad\"\"\"\n",
    "        pass\n",
    "    \n",
    "class LinearLayer(Layer):\n",
    "    \"\"\"The linear layer performs a linear transformation to its input.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_in, n_out):\n",
    "        \"\"\"Initialize hidden layer parameters.\n",
    "        n_in is the number of input variables.\n",
    "        n_out is the number of output variables.\"\"\"\n",
    "        self.W = np.random.randn(n_in, n_out) * 0.1\n",
    "        self.b = np.zeros(n_out)\n",
    "        \n",
    "    def get_params_iter(self):\n",
    "        \"\"\"Return an iterator over the parameters.\"\"\"\n",
    "        return itertools.chain(np.nditer(self.W, op_flags=['readwrite']),\n",
    "                               np.nditer(self.b, op_flags=['readwrite']))\n",
    "    \n",
    "    def get_params_array(self):\n",
    "        \"\"\"Return arrays of the parameters.\"\"\"\n",
    "        return np.array(self.W), np.array(self.b)\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        \"\"\"Perform the forward step linear transformation.\"\"\"\n",
    "        return X.dot(self.W) + self.b\n",
    "        \n",
    "    def get_params_grad(self, X, output_grad):\n",
    "        \"\"\"Return a list of gradients over the parameters.\"\"\"\n",
    "        JW = X.T.dot(output_grad)\n",
    "        Jb = np.sum(output_grad, axis=0)\n",
    "        return [g for g in itertools.chain(np.nditer(JW), np.nditer(Jb))]\n",
    "    \n",
    "    def get_input_grad(self, Y, output_grad):\n",
    "        \"\"\"Return the gradient at the inputs of this layer.\"\"\"\n",
    "        return output_grad.dot(self.W.T)\n",
    "    \n",
    "class LogisticLayer(Layer):\n",
    "    \"\"\"The logistic layer applies the logistic function to its inputs.\"\"\"\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        \"\"\"Perform the forward step transformation.\"\"\"\n",
    "        return logistic(X)\n",
    "    \n",
    "    def get_input_grad(self, Y, output_grad):\n",
    "        \"\"\"Return the gradient at the inputs of this layer.\"\"\"\n",
    "        return np.multiply(logistic_deriv(Y), output_grad)\n",
    "    \n",
    "class ReLULayer(Layer):\n",
    "    \"\"\"The ReLU layer applies the Rectified Linear Units function to its inputs.\"\"\"\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        \"\"\"Perform the forward step transformation.\"\"\"\n",
    "        return ReLU(X)\n",
    "    \n",
    "    def get_input_grad(self, Y, output_grad):\n",
    "        \"\"\"Return the gradient at the inputs of this layer.\"\"\"\n",
    "        return np.multiply(ReLU_Der(Y), output_grad)\n",
    "    \n",
    "class SoftmaxOutputLayer(Layer):\n",
    "    \"\"\"The softmax output layer computes the classification propabilities at the output.\"\"\"\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        \"\"\"Perform the forward step transformation.\"\"\"\n",
    "        return softmax(X)\n",
    "    \n",
    "    def get_input_grad(self, Y, T):\n",
    "        \"\"\"Return the gradient at the inputs of this layer.\"\"\"\n",
    "        return (Y - T) / Y.shape[0]\n",
    "    \n",
    "    def get_cost(self, Y, T):\n",
    "        \"\"\"Return the cost at the output of this output layer.\"\"\"\n",
    "        return - np.multiply(T, np.log(Y)).sum() / Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN LAYER 1 NEURONS: 500\n",
      "HIDDEN LAYER 2 NEURONS: 150\n"
     ]
    }
   ],
   "source": [
    "# Define a sample model to be trained on the data\n",
    "hidden_neurons_1 = 500  # Number of neurons in the first hidden-layer\n",
    "hidden_neurons_2 = 150  # Number of neurons in the second hidden-layer\n",
    "print(\"HIDDEN LAYER 1 NEURONS: {}\".format(hidden_neurons_1))\n",
    "print(\"HIDDEN LAYER 2 NEURONS: {}\".format(hidden_neurons_2))\n",
    "# Create the model\n",
    "layers_SG = [] # Define a list of layers\n",
    "#layers_ReLU = []\n",
    "layers_ReLU_SG = []\n",
    "# Add first hidden layer\n",
    "layers_SG.append(LinearLayer(X_train.shape[1], hidden_neurons_1))\n",
    "layers_SG.append(LogisticLayer())\n",
    "\n",
    "#DEACTIVATED UNTIL THE DYING ReLU PROBLEM IS FIXED\n",
    "#layers_ReLU.append(LinearLayer(X_train.shape[1], hidden_neurons_1))\n",
    "#layers_ReLU.append(ReLULayer())\n",
    "\n",
    "layers_ReLU_SG.append(LinearLayer(X_train.shape[1], hidden_neurons_1))\n",
    "layers_ReLU_SG.append(ReLULayer())\n",
    "# Add second hidden layer\n",
    "layers_SG.append(LinearLayer(hidden_neurons_1, hidden_neurons_2))\n",
    "layers_SG.append(LogisticLayer())\n",
    "\n",
    "#DEACTIVATED UNTIL THE DYING ReLU PROBLEM IS FIXED\n",
    "#layers_ReLU.append(LinearLayer(hidden_neurons_1, hidden_neurons_2))\n",
    "#layers_ReLU.append(ReLULayer())\n",
    "\n",
    "layers_ReLU_SG.append(LinearLayer(hidden_neurons_1, hidden_neurons_2))\n",
    "layers_ReLU_SG.append(LogisticLayer())\n",
    "# Add output layer\n",
    "layers_SG.append(LinearLayer(hidden_neurons_2, T_train.shape[1]))\n",
    "layers_SG.append(SoftmaxOutputLayer())\n",
    "\n",
    "#DEACTIVATED UNTIL THE DYING ReLU PROBLEM IS FIXED\n",
    "#layers_ReLU.append(LinearLayer(hidden_neurons_2, T_train.shape[1]))\n",
    "#layers_ReLU.append(SoftmaxOutputLayer())\n",
    "\n",
    "layers_ReLU_SG.append(LinearLayer(hidden_neurons_2, T_train.shape[1]))\n",
    "layers_ReLU_SG.append(SoftmaxOutputLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the forward propagation step as a method.\n",
    "def forward_step(input_samples, layers):\n",
    "    \"\"\"\n",
    "    Compute and return the forward activation of each layer in layers.\n",
    "    Input:\n",
    "        input_samples: A matrix of input samples (each row is an input vector)\n",
    "        layers: A list of Layers\n",
    "    Output:\n",
    "        A list of activations where the activation at each index i+1 corresponds to\n",
    "        the activation of layer i in layers. activations[0] contains the input samples.  \n",
    "    \"\"\"\n",
    "    activations = [input_samples] # List of layer activations\n",
    "    # Compute the forward activations for each layer starting from the first\n",
    "    X = input_samples\n",
    "    for layer in layers:\n",
    "        Y = layer.get_output(X)  # Get the output of the current layer\n",
    "        activations.append(Y)  # Store the output for future processing\n",
    "        X = activations[-1]  # Set the current input as the activations of the previous layer\n",
    "    return activations  # Return the activations of each layer\n",
    "\n",
    "# Define the backward propagation step as a method\n",
    "def backward_step(activations, targets, layers):\n",
    "    \"\"\"\n",
    "    Perform the backpropagation step over all the layers and return the parameter gradients.\n",
    "    Input:\n",
    "        activations: A list of forward step activations where the activation at \n",
    "            each index i+1 corresponds to the activation of layer i in layers. \n",
    "            activations[0] contains the input samples. \n",
    "        targets: The output targets of the output layer.\n",
    "        layers: A list of Layers corresponding that generated the outputs in activations.\n",
    "    Output:\n",
    "        A list of parameter gradients where the gradients at each index corresponds to\n",
    "        the parameters gradients of the layer at the same index in layers. \n",
    "    \"\"\"\n",
    "    param_grads = collections.deque()  # List of parameter gradients for each layer\n",
    "    output_grad = None  # The error gradient at the output of the current layer\n",
    "    # Propagate the error backwards through all the layers.\n",
    "    #  Use reversed to iterate backwards over the list of layers.\n",
    "    for layer in reversed(layers):   \n",
    "        Y = activations.pop()  # Get the activations of the last layer on the stack\n",
    "        # Compute the error at the output layer.\n",
    "        # The output layer error is calculated different then hidden layer error.\n",
    "        if output_grad is None:\n",
    "            input_grad = layer.get_input_grad(Y, targets)\n",
    "        else:  # output_grad is not None (layer is not output layer)\n",
    "            input_grad = layer.get_input_grad(Y, output_grad)\n",
    "        # Get the input of this layer (activations of the previous layer)\n",
    "        X = activations[-1]\n",
    "        # Compute the layer parameter gradients used to update the parameters\n",
    "        grads = layer.get_params_grad(X, output_grad)\n",
    "        param_grads.appendleft(grads)\n",
    "        # Compute gradient at output of previous layer (input of current layer):\n",
    "        output_grad = input_grad\n",
    "    return list(param_grads)  # Return the parameter gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No gradient errors found\n"
     ]
    }
   ],
   "source": [
    "# Perform gradient checking\n",
    "nb_samples_gradientcheck = 10 # Test the gradients on a subset of the data\n",
    "X_temp = X_train[0:nb_samples_gradientcheck,:]\n",
    "T_temp = T_train[0:nb_samples_gradientcheck,:]\n",
    "# Get the parameter gradients with backpropagation\n",
    "activations_SG = forward_step(X_temp, layers_SG)\n",
    "param_grads_SG = backward_step(activations_SG, T_temp, layers_SG)\n",
    "\n",
    "#activations_ReLU = forward_step(X_temp, layers_ReLU)\n",
    "#param_grads_ReLU = backward_step(activations_ReLU, T_temp, layers_ReLU)\n",
    "\n",
    "#activations_ReLU_SG = forward_step(X_temp, layers_ReLU_SG)\n",
    "#param_grads_ReLU_SG = backward_step(activations_ReLU_SG, T_temp, layers_ReLU_SG)\n",
    "\n",
    "# Set the small change to compute the numerical gradient\n",
    "eps = 0.0001\n",
    "# Compute the numerical gradients of the parameters in all layers.\n",
    "for idx in range(len(layers_SG)):\n",
    "    layer_SG = layers_SG[idx]\n",
    "#    layer_ReLU = layers_ReLU[idx]\n",
    "#    layer_ReLU_SG = layers_ReLU_SG[idx]\n",
    "    \n",
    "    layer_backprop_grads_SG = param_grads_SG[idx]\n",
    "#    layer_backprop_grads_ReLU = param_grads_ReLU[idx]\n",
    "#    layer_backprop_grads_ReLU_SG = param_grads_ReLU_SG[idx]\n",
    "    # Compute the numerical gradient for each parameter in the SG layer\n",
    "    for p_idx, param in enumerate(layer_SG.get_params_iter()):\n",
    "        grad_backprop = layer_backprop_grads_SG[p_idx]\n",
    "        # + eps\n",
    "        param += eps\n",
    "        plus_cost = layers_SG[-1].get_cost(forward_step(X_temp, layers_SG)[-1], T_temp)\n",
    "        # - eps\n",
    "        param -= 2 * eps\n",
    "        min_cost = layers_SG[-1].get_cost(forward_step(X_temp, layers_SG)[-1], T_temp)\n",
    "        # reset param value\n",
    "        param += eps\n",
    "        # calculate numerical gradient\n",
    "        grad_num = (plus_cost - min_cost)/(2*eps)\n",
    "        # Raise error if the numerical grade is not close to the backprop gradient\n",
    "        if not math.isclose(grad_num, grad_backprop, rel_tol=1e-04, abs_tol=1e-05):\n",
    "            raise ValueError('SG NN: Numerical gradient of {:.6f} is not close to the backpropagation gradient of {:.6f}!'.format(float(grad_num), float(grad_backprop)))\n",
    "#DEACTIVATED UNTIL THE DYING ReLU PROBLEM IS FIXED\n",
    "    # Compute the numerical gradient for each parameter in the ReLU layer\n",
    "#    for p_idx, param in enumerate(layer_ReLU.get_params_iter()):\n",
    "#        grad_backprop = layer_backprop_grads_ReLU[p_idx]\n",
    "#        # + eps\n",
    "#        param += eps\n",
    "#        plus_cost = layers_ReLU[-1].get_cost(forward_step(X_temp, layers_ReLU)[-1], T_temp)\n",
    "#        # - eps\n",
    "#        param -= 2 * eps\n",
    "#        min_cost = layers_ReLU[-1].get_cost(forward_step(X_temp, layers_ReLU)[-1], T_temp)\n",
    "#        # reset param value\n",
    "#        param += eps\n",
    "#        # calculate numerical gradient\n",
    "#        grad_num = (plus_cost - min_cost)/(2*eps)\n",
    "#        # Raise error if the numerical grade is not close to the backprop gradient\n",
    "#        if not math.isclose(grad_num, grad_backprop, rel_tol=1e-04, abs_tol=1e-05):\n",
    "#            raise ValueError('ReLU NN: Numerical gradient of {:.6f} is not close to the backpropagation gradient of {:.6f}!'.format(float(grad_num), float(grad_backprop)))\n",
    "    # Compute the numerical gradient for each parameter in the ReLU_SG layer    \n",
    "#    for p_idx, param in enumerate(layer_ReLU_SG.get_params_iter()):\n",
    "#        grad_backprop = layer_backprop_grads_ReLU_SG[p_idx]\n",
    "#        # + eps\n",
    "#        param += eps\n",
    "#        plus_cost = layers_ReLU_SG[-1].get_cost(forward_step(X_temp, layers_ReLU_SG)[-1], T_temp)\n",
    "#        # - eps\n",
    "#        param -= 2 * eps\n",
    "#        min_cost = layers_ReLU_SG[-1].get_cost(forward_step(X_temp, layers_ReLU_SG)[-1], T_temp)\n",
    "#        # reset param value\n",
    "#        param += eps\n",
    "#        # calculate numerical gradient\n",
    "#        grad_num = (plus_cost - min_cost)/(2*eps)\n",
    "#        # Raise error if the numerical grade is not close to the backprop gradient\n",
    "#        if not math.isclose(grad_num, grad_backprop, rel_tol=1e-03, abs_tol=1e-04):\n",
    "#            raise ValueError('ReLU_SG NN: Numerical gradient of {:.6f} is not close to the backpropagation gradient of {:.6f}!'.format(float(grad_num), float(grad_backprop)))\n",
    "print('No gradient errors found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the minibatches\n",
    "batch_size = 500  # Approximately 500 samples per batch\n",
    "nb_of_batches = X_train.shape[0] / batch_size  # Number of batches\n",
    "# Create batches (X,Y) from the training set\n",
    "XT_batches = list(zip(\n",
    "    np.array_split(X_train, nb_of_batches, axis=0),  # X samples\n",
    "    np.array_split(T_train, nb_of_batches, axis=0)))  # Y targets\n",
    "# Define a method to update the parameters\n",
    "def update_params(layers, param_grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Function to update the parameters of the given layers with the given gradients\n",
    "    by gradient descent with the given learning rate.\n",
    "    \"\"\"\n",
    "    for layer, layer_backprop_grads in zip(layers, param_grads):\n",
    "        for param, grad in zip(layer.get_params_iter(), layer_backprop_grads):\n",
    "            # The parameter returned by the iterator point to the memory space of\n",
    "            #  the original layer and can thus be modified inplace.\n",
    "            param -= learning_rate * grad  # Update each parameter\n",
    "def get_accuracy(output_activation, T):\n",
    "    true_pred = 0\n",
    "    for idx, pred in enumerate(output_activation):\n",
    "        pred_digit = np.argmax(pred)\n",
    "        label_digit = np.argmax(T[idx])\n",
    "        if pred_digit == label_digit:\n",
    "            true_pred += 1\n",
    "    accuracy = (true_pred/len(T))*100\n",
    "    return accuracy\n",
    "\n",
    "def get_certainty(output_activation):\n",
    "    certainty = []\n",
    "    for idx, pred in enumerate(output_activation):\n",
    "        certainty.append((np.amax(pred))*100)\n",
    "    av_certainty = sum(certainty)/float(len(certainty))\n",
    "    return av_certainty, certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backpropagation\n",
    "max_nb_of_iterations = 300  # Train for a maximum of 300 iterations (Epochs)\n",
    "learning_rate = 0.1  # Gradient descent learning rate\n",
    "\n",
    "def train_network(layers):\n",
    "    # initalize some lists to store the cost for future analysis        \n",
    "    minibatch_costs = []\n",
    "    training_costs = []\n",
    "    train_accuracy = []\n",
    "    train_certainty = []\n",
    "    validation_costs = []\n",
    "    val_accuracy = []\n",
    "    val_certainty = []\n",
    "    # Train for the maximum number of iterations\n",
    "    start_time = time.time()\n",
    "    for iteration in range(max_nb_of_iterations):\n",
    "        print(\"Starting Epoch: {}\".format(iteration+1))\n",
    "        for X, T in XT_batches:  # For each minibatch sub-iteration\n",
    "            activations = forward_step(X, layers)  # Get the activations\n",
    "            minibatch_cost = layers[-1].get_cost(activations[-1], T)  # Get cost\n",
    "            minibatch_costs.append(minibatch_cost)\n",
    "            param_grads = backward_step(activations, T, layers)  # Get the gradients\n",
    "            update_params(layers, param_grads, learning_rate)  # Update the parameters\n",
    "        # Get full training cost for future analysis (plots)\n",
    "        activations = forward_step(X_train, layers)\n",
    "        train_accuracy.append(get_accuracy(activations[-1], T_train))\n",
    "        train_certainty.append(get_certainty(activations[-1])[0])\n",
    "        train_cost = layers[-1].get_cost(activations[-1], T_train)\n",
    "        training_costs.append(train_cost)\n",
    "        # Get full validation cost\n",
    "        activations = forward_step(X_validation, layers)\n",
    "        val_accuracy.append(get_accuracy(activations[-1], T_validation))\n",
    "        val_certainty.append(get_certainty(activations[-1])[0])\n",
    "        validation_cost = layers[-1].get_cost(activations[-1], T_validation)\n",
    "        validation_costs.append(validation_cost)\n",
    "        if len(validation_costs) > 3:\n",
    "            # Stop training if the cost on the validation set doesn't decrease\n",
    "            #  for 3 iterations\n",
    "            if validation_costs[-1] >= validation_costs[-2] >= validation_costs[-3]:\n",
    "                print(\"CONVERGENCE ACHIEVED!\")\n",
    "                break\n",
    "    end_time = time.time()\n",
    "    t_time = end_time - start_time\n",
    "    nb_of_iterations = iteration + 1  # The number of iterations that have been executed\n",
    "    return layers, nb_of_iterations, minibatch_costs, training_costs, validation_costs, train_accuracy, train_certainty, val_accuracy, val_certainty, t_time\n",
    "\n",
    "def plot_result(nb_of_iterations, minibatch_costs, training_costs, validation_costs, train_accuracy, train_certainty, val_accuracy, val_certainty, t_time):    \n",
    "    # Plot the minibatch, full training set, and validation costs\n",
    "    minibatch_x_inds = np.linspace(0, nb_of_iterations, num=nb_of_iterations*nb_of_batches)\n",
    "    iteration_x_inds = np.linspace(1, nb_of_iterations, num=nb_of_iterations)\n",
    "    # Plot the cost over the iterations\n",
    "    plt.plot(minibatch_x_inds, minibatch_costs, 'k-', linewidth=0.5, label='cost minibatches')\n",
    "    plt.plot(iteration_x_inds, training_costs, 'r-', linewidth=2, label='cost full training set')\n",
    "    plt.plot(iteration_x_inds, validation_costs, 'b-', linewidth=3, label='cost validation set')\n",
    "    # Add labels to the plot\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('$\\\\xi$', fontsize=15)\n",
    "    plt.title('Decrease of cost over backprop epochs')\n",
    "    plt.legend()\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((0,nb_of_iterations,0,1.5))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    #Plot accuracy\n",
    "    plt.plot(iteration_x_inds, train_accuracy, 'r-', linewidth=2, label='accuracy full training set')\n",
    "    plt.plot(iteration_x_inds, val_accuracy, 'b-', linewidth=3, label='accuracy validation set')\n",
    "    # Add labels to the plot\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('Accuracy', fontsize=15)\n",
    "    plt.title('Increase of accuracy over backprop epochs')\n",
    "    plt.legend()\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((0,nb_of_iterations,0,100))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    #Plot certainty\n",
    "    plt.plot(iteration_x_inds, train_certainty, 'r-', linewidth=2, label='certainty full training set')\n",
    "    plt.plot(iteration_x_inds, val_certainty, 'b-', linewidth=3, label='certainty validation set')\n",
    "    # Add labels to the plot\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('Certainty', fontsize=15)\n",
    "    plt.title('Increase of certainty over backprop epochs')\n",
    "    plt.legend()\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((0,nb_of_iterations,0,100))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    #Print time for training\n",
    "    m, s = divmod(t_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    print(\"NUMBER OF TRAINING EPOCHS: {}\".format(nb_of_iterations))\n",
    "    print(\"OVERALL TIME FOR TRAINING & VALIDATION: {}h:{}m:{}s\".format(h,m,s))\n",
    "    print(\"LAST THREE VALIDATION COSTS: {} {} {}\".format(validation_costs[-3], validation_costs[-2], validation_costs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 1\n",
      "Starting Epoch: 2\n",
      "Starting Epoch: 3\n",
      "Starting Epoch: 4\n",
      "Starting Epoch: 5\n",
      "Starting Epoch: 6\n",
      "Starting Epoch: 7\n",
      "Starting Epoch: 8\n",
      "Starting Epoch: 9\n",
      "Starting Epoch: 10\n",
      "Starting Epoch: 11\n",
      "Starting Epoch: 12\n",
      "Starting Epoch: 13\n",
      "Starting Epoch: 14\n",
      "Starting Epoch: 15\n",
      "Starting Epoch: 16\n",
      "Starting Epoch: 17\n",
      "Starting Epoch: 18\n",
      "Starting Epoch: 19\n",
      "Starting Epoch: 20\n",
      "Starting Epoch: 21\n",
      "Starting Epoch: 22\n",
      "Starting Epoch: 23\n",
      "Starting Epoch: 24\n",
      "Starting Epoch: 25\n",
      "Starting Epoch: 26\n",
      "Starting Epoch: 27\n",
      "Starting Epoch: 28\n",
      "Starting Epoch: 29\n",
      "Starting Epoch: 30\n",
      "Starting Epoch: 31\n",
      "Starting Epoch: 32\n",
      "Starting Epoch: 33\n",
      "Starting Epoch: 34\n"
     ]
    }
   ],
   "source": [
    "#layers_SG, nb_of_iterations_SG, minibatch_costs_SG, training_costs_SG, validation_costs_SG, train_accuracy_SG, train_certainty_SG, val_accuracy_SG, val_certainty_SG, time_SG = train_network(layers_SG)\n",
    "layers_ReLU_SG, nb_of_iterations_ReLU_SG, minibatch_costs_ReLU_SG, training_costs_ReLU_SG, validation_costs_ReLU_SG, train_accuracy_ReLU_SG, train_certainty_ReLU_SG, val_accuracy_ReLU_SG, val_certainty_ReLU_SG, time_ReLU_SG = train_network(layers_ReLU_SG)\n",
    "\n",
    "#plot_result(nb_of_iterations_SG, minibatch_costs_SG, training_costs_SG, validation_costs_SG, train_accuracy_SG, train_certainty_SG, val_accuracy_SG, val_certainty_SG, time_SG)\n",
    "plot_result(nb_of_iterations_ReLU_SG, minibatch_costs_ReLU_SG, training_costs_ReLU_SG, validation_costs_ReLU_SG, train_accuracy_ReLU_SG, train_certainty_ReLU_SG, val_accuracy_ReLU_SG, val_certainty_ReLU_SG, time_ReLU_SG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_network(layers, T_test):\n",
    "    # Get results of test data\n",
    "    y_true = np.argmax(T_test, axis=1)  # Get the target outputs\n",
    "    activations = forward_step(X_test, layers)  # Get activation of test samples\n",
    "    y_pred = np.argmax(activations[-1], axis=1)  # Get the predictions made by the network\n",
    "    test_accuracy = metrics.accuracy_score(y_true, y_pred)  # Test set accuracy\n",
    "    print('The accuracy on the test set is {:.2f}'.format(test_accuracy))\n",
    "    test_accuracy = get_accuracy(activations[-1], T_test)\n",
    "    av_test_certainty, test_certainty = get_certainty(activations[-1])\n",
    "    print(\"TEST ACCURACY: {}%\".format(test_accuracy))\n",
    "    print(\"AVERAGE TEST CERTAINTY: {}%\".format(av_test_certainty))\n",
    "    return y_true, y_pred, test_accuracy, av_test_certainty, test_certainty\n",
    "\n",
    "def plot_confusion_table(y_true, y_pred):\n",
    "    # Show confusion table\n",
    "    conf_matrix = metrics.confusion_matrix(y_true, y_pred, labels=None)  # Get confustion matrix\n",
    "    # Plot the confusion table\n",
    "    class_names = ['${:d}$'.format(x) for x in range(0, 10)]  # Digit class names\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    # Show class labels on each axis\n",
    "    ax.xaxis.tick_top()\n",
    "    major_ticks = range(0,10)\n",
    "    minor_ticks = [x + 0.5 for x in range(0, 10)]\n",
    "    ax.xaxis.set_ticks(major_ticks, minor=False)\n",
    "    ax.yaxis.set_ticks(major_ticks, minor=False)\n",
    "    ax.xaxis.set_ticks(minor_ticks, minor=True)\n",
    "    ax.yaxis.set_ticks(minor_ticks, minor=True)\n",
    "    ax.xaxis.set_ticklabels(class_names, minor=False, fontsize=15)\n",
    "    ax.yaxis.set_ticklabels(class_names, minor=False, fontsize=15)\n",
    "    # Set plot labels\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "    fig.suptitle('Confusion table', y=1.03, fontsize=15)\n",
    "    # Show a grid to seperate digits\n",
    "    ax.grid(b=True, which=u'minor')\n",
    "    # Color each grid cell according to the number classes predicted\n",
    "    ax.imshow(conf_matrix, interpolation='nearest', cmap='binary')\n",
    "    # Show the number of samples in each cell\n",
    "    for x in range(conf_matrix.shape[0]):\n",
    "        for y in range(conf_matrix.shape[1]):\n",
    "            color = 'w' if x == y else 'k'\n",
    "            ax.text(x, y, conf_matrix[y,x], ha=\"center\", va=\"center\", color=color)       \n",
    "    plt.show()\n",
    "\n",
    "def SHOW_IMAGES(INPUT_FEATURES, LABELS, P_LABELS, CERTAINTY):\n",
    "    \n",
    "    print(\"Would You Like to See Image Prediction?\")\n",
    "    USER_I = input()\n",
    "    if (USER_I == 'Yes' or USER_I == 'Y' or USER_I == 'y'):\n",
    "        ROW = 4\n",
    "        COLUMN = 5\n",
    "        n_per_frame = ROW * COLUMN\n",
    "        n_frames = len(INPUT_FEATURES)/(n_per_frame)\n",
    "        for frame in range(int(n_frames)):\n",
    "            for i in range(ROW * COLUMN):\n",
    "                image = INPUT_FEATURES[frame*n_per_frame+i].reshape(28, 28)   # not necessary to reshape if ndim is set to 2\n",
    "                plt.subplot(ROW, COLUMN, i+1)          # subplot with size (width 3, height 5)\n",
    "                plt.imshow(image, cmap='gray')  # cmap='gray' is for black and white picture.\n",
    "                plt.title('P [{}]({}%)'.format(P_LABELS[frame*n_per_frame+i], int(CERTAINTY[frame*n_per_frame+i])))\n",
    "                #plt.set_xlabel('L({})'.format(LABELS[frame*n_per_frame+i]))\n",
    "                plt.axis('off')  # do not show axis value\n",
    "            plt.tight_layout()   # automatic padding between subplots\n",
    "            #pad=0, w_pad=0, h_pad=2\n",
    "            #plt.savefig('images/mnist_plot.png')\n",
    "            plt.show()\n",
    "            if frame == (n_frames - 1):\n",
    "                print('Showed You All!')\n",
    "                break\n",
    "            print(\"Would You Like to See Some More?\")\n",
    "            USER_I = input()\n",
    "            if (USER_I == 'No' or USER_I == 'N' or USER_I == 'n'):\n",
    "                print(\"Enough is Enough I Guess!\")\n",
    "                break\n",
    "    elif (USER_I == 'No' or USER_I == 'N' or USER_I == 'n'):\n",
    "        print(\"Well Your Loss!\")\n",
    "    else: print(\"Did not get that, try y/n\")\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Work\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the test set is 0.97\n",
      "TEST ACCURACY: 96.75%\n",
      "AVERAGE TEST CERTAINTY: 97.01830792766184%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAEhCAYAAAByXmWMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPDk45yL9ByXsEPi0zDPgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9d7f908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would You Like to See Image Prediction?\n",
      "y\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEYCAYAAACDV/v0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npoP4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1994fe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would You Like to See Some More?\n",
      "n\n",
      "Enough is Enough I Guess!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels_output, pred_output_SG, test_accuracy, test_certainty, certainty_vec = test_network(layers_SG, T_test)\n",
    "labels_output, pred_output_ReLU_SG, test_accuracy, test_certainty, certainty_vec = test_network(layers_ReLU_SG, T_test)\n",
    "\n",
    "#plot_confusion_table(labels_output, pred_output_SG)\n",
    "plot_confusion_table(labels_output, pred_output_ReLU_SG)\n",
    "\n",
    "SHOW_IMAGES(X_test, labels_output, pred_output_ReLU_SG, certainty_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers_ReLU_SG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b3092cda0da1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Write the model into files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers_ReLU_SG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers_ReLU_SG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mw3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers_ReLU_SG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers_ReLU_SG' is not defined"
     ]
    }
   ],
   "source": [
    "#Write the model into files\n",
    "w1, b1 = layers_ReLU_SG[0].get_params_array()\n",
    "w2, b2 = layers_ReLU_SG[2].get_params_array()\n",
    "w3, b3 = layers_ReLU_SG[4].get_params_array()\n",
    "\n",
    "with open(\"ReLU_SG_HL_1_W.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerows(w1)\n",
    "    \n",
    "with open(\"ReLU_SG_HL_1_b.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerow(b1)\n",
    "\n",
    "with open(\"ReLU_SG_HL_2_W.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerows(w2)\n",
    "    \n",
    "with open(\"ReLU_SG_HL_2_b.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerow(b2)\n",
    "    \n",
    "with open(\"ReLU_SG_OL_W.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerows(w3)\n",
    "    \n",
    "with open(\"ReLU_SG_OL_b.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerow(b3)\n",
    "    \n",
    "w1, b1 = layers_SG[0].get_params_array()\n",
    "w2, b2 = layers_SG[2].get_params_array()\n",
    "w3, b3 = layers_SG[4].get_params_array()\n",
    "\n",
    "with open(\"SG_HL_1_W.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerows(w1)\n",
    "    \n",
    "with open(\"SG_HL_1_b.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerow(b1)\n",
    "\n",
    "with open(\"SG_HL_2_W.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerows(w2)\n",
    "    \n",
    "with open(\"SG_HL_2_b.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerow(b2)\n",
    "    \n",
    "with open(\"SG_OL_W.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerows(w3)\n",
    "    \n",
    "with open(\"SG_OL_b.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator='},\\n{')\n",
    "    csvWriter.writerow(b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1, b1 = layers_ReLU_SG[0].get_params_array()\n",
    "w2, b2 = layers_ReLU_SG[2].get_params_array()\n",
    "w3, b3 = layers_ReLU_SG[4].get_params_array()\n",
    "\n",
    "with open(\"ReLU_SG_HL_1_W.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator=',')\n",
    "    csvWriter.writerows(w1)\n",
    "    \n",
    "with open(\"ReLU_SG_HL_1_b.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator=',')\n",
    "    csvWriter.writerow(b1)\n",
    "\n",
    "with open(\"ReLU_SG_HL_2_W.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator=',')\n",
    "    csvWriter.writerows(w2)\n",
    "    \n",
    "with open(\"ReLU_SG_HL_2_b.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator=',')\n",
    "    csvWriter.writerow(b2)\n",
    "    \n",
    "with open(\"ReLU_SG_OL_W.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator=',')\n",
    "    csvWriter.writerows(w3)\n",
    "    \n",
    "with open(\"ReLU_SG_OL_b.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator=',')\n",
    "    csvWriter.writerow(b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"T_TEST_DATA.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator=',')\n",
    "    csvWriter.writerows(T_test)\n",
    "\n",
    "with open(\"X_TEST_DATA.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',',lineterminator=',')\n",
    "    csvWriter.writerows(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
